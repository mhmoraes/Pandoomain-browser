include: "rules/globals.smk"
include: "rules/download.smk"


rule all:
    input:
        f"{RESULTS}/absence_presence.tsv",


rule hmmer_input:
    input:
        rules.download_genomes.output.genomes,
    output:
       f"{RESULTS}/.input_faas.txt",
    params:
        results=f"{RESULTS}",
    shell:
        """
fd -HI -e faa '^GC' {params} >| {output}
"""


rule hmmer:
    input:
        faas=rules.hmmer_input.output,
    output:
        tsv=ensure(f"{RESULTS}/hmmer.tsv", non_empty=True),
    params:
        queries=f"{IN_QUERIES}",
    shell:
        r"""
workflow/scripts/hmmer.py {params} {input} {output}
"""



rule get_neighbors:
    input:
        hmmer=rules.hmmer.output,
    output:
        neighbors=ensure(f"{RESULTS}/neighbors.tsv", non_empty=True),
    threads: workflow.cores
    params:
        N=N_NEIGHBORS,
        gdir=f"{RESULTS}/genomes",  # Se convertira en output
    shell:
        """
workflow/scripts/neighbors.R {threads} {params} {input} >| {output}
"""


rule all_faa:
    input:
        neighbors=rules.get_neighbors.output,
    output:
        faa=f"{RESULTS}/all.faa",
    params:
        faa_width=FAA_WIDTH,
        db=f"{RESULTS}/genomes",
    threads: workflow.cores
    shell:
        r"""
workflow/scripts/harvest.R {params} {threads} {input} >| {output}
"""


rule split_faa:
    input:
        faa=rules.all_faa.output,
    output:
        sentinel=f"{RESULTS}/.pieces_faa/split_faa.sentinel",
    params:
        pieces=f"{RESULTS}/.pieces_faa",
        batch_size=f"{BATCH_SIZE}",
        faa_width=f"{FAA_WIDTH}",
    run:
        #!/usr/bin/env python
        from datetime import datetime
        from pathlib import Path
        from shutil import rmtree

        from Bio import SeqIO

        START = datetime.today()

        IN_FAA = Path(f"{input.faa}")
        OUT_PIECES = Path(f"{params.pieces}")
        OUT_SENTINEL = Path(f"{output.sentinel}")
        BATCH_SIZE = int(f"{params.batch_size}")
        FAA_WIDTH = int(f"{params.faa_width}")
        FORMAT = "fasta"

        # main
        in_faa = SeqIO.parse(IN_FAA, FORMAT)
        if OUT_PIECES.exists():
            rmtree(OUT_PIECES)
        OUT_PIECES.mkdir()
        batch = []
        ibatch = 0


        def write(batch, out_file, wrap=60):
            with open(out_file, "w") as hout:
                w = SeqIO.FastaIO.FastaWriter(hout, wrap=wrap)
                for seq in batch:
                    w.write_record(seq)


        for idx, seq in enumerate(in_faa):
            batch.append(seq)

            if (idx + 1) % BATCH_SIZE == 0:
                ibatch += 1
                piece = OUT_PIECES / f"{ibatch}.faa"
                write(batch, piece, FAA_WIDTH)
                batch = []

        if len(batch) > 0:
            ibatch += 1
            piece = OUT_PIECES / f"{ibatch}.faa"
            write(batch, piece, FAA_WIDTH)

        END = datetime.today()
        with open(str(OUT_SENTINEL), "w") as h_sentinel:
            h_sentinel.write(f"{END- START}\n")


rule interproscan:
    input:
        sentinel=f"{rules.split_faa.output.sentinel}",
    output:
        tsv=f"{RESULTS}/.iscan_raw.tsv",
    params:
        tmp="/tmp",
        pieces=f"{RESULTS}/.pieces_iscan",
        in_dir=f"{rules.split_faa.params.pieces}",
    threads: workflow.cores
    cache: True
    run:
        import re
        import shutil
        import subprocess as sp
        from pathlib import Path

        IN_DIR = Path(f"{params.in_dir}")
        OUT_FILE = Path(f"{output}")

        OUT_DIR = Path(f"{params.pieces}")
        CPUS = int(f"{threads}")
        ISCAN_TMP = Path(f"{params.tmp}")


        def cat(*files, out_file) -> None:

            with open(out_file, "wb") as hout:
                for file in files:
                    with open(file, "rb") as hfile:
                        shutil.copyfileobj(hfile, hout)


        def gen_cmd(in_faa):
            """
    Output formats:
    Default for protein sequences are TSV, XML and GFF3
    """
            cmd = [
                "interproscan.sh",
                "--input",
                str(in_faa),
                "--cpu",
                str(CPUS),
                "--tempdir",
                str(ISCAN_TMP),
                "--goterms",
                "--enable-tsv-residue-annot",
                "--applications",
                "Pfam",
            ]
            return cmd

            # main


        if OUT_DIR.exists():
            shutil.rmtree(OUT_DIR)
        OUT_DIR.mkdir()
        in_faas = [
            (IN_DIR / i).resolve()
            for i in os.listdir(IN_DIR)
            if re.search(r"\d+\.faa$", i)
        ]

        for in_faa in in_faas:
            sp.run(gen_cmd(in_faa), cwd=OUT_DIR, check=True)

        out_tsvs = [
            OUT_DIR / i for i in os.listdir(OUT_DIR) if re.search(r"\w+\.tsv$", i)
        ]

        cat(*out_tsvs, out_file=OUT_FILE)


rule add_header_iscan:
    input:
        tsv=rules.interproscan.output,
    output:
        tsv=f"{RESULTS}/iscan.tsv",
    shell:
        """
# Annotate headers
workflow/scripts/add_header_iscan.R {params} {input} >| {output}
"""


rule get_archs:
    input:
        tsv=rules.add_header_iscan.output,
    output:
        archs=f"{RESULTS}/archs.tsv",
        pidrow=f"{RESULTS}/archs_pidrow.tsv",
        code=f"{RESULTS}/archs_code.tsv",
    shell:
        """
workflow/scripts/archs.R {input} {output}
"""


rule get_absence_presence:
    input:
        taxa=rules.join_genomes_taxallnomy.output,
        proteins=rules.get_neighbors.output,
        domains=rules.get_archs.output.archs,
    output:
        TGPD=f"{RESULTS}/TGPD.tsv",
        absence_presence=f"{RESULTS}/absence_presence.tsv",
    shell:
        """
workflow/scripts/absence_presence.R {input} {output}
"""
