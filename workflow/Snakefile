include: "rules/globals.smk"
include: "rules/download.smk"


rule all:
    input:
        f"{RESULTS}/absence_presence.tsv",
        # Browser visualizer files
        f"{RESULTS}/browser_files/iscan.db",
        f"{RESULTS}/browser_files/metadata.db",
        f"{RESULTS}/browser_files/neighbors.db",


rule hmmer:
    input:
        f"{RESULTS}/genomes/genomes.tsv",
    output:
        hmmer=ensure(f"{RESULTS}/hmmer.tsv", non_empty=True),
    params:
        queries=f"{IN_QUERIES}",
    shell:
        r"""
workflow/scripts/hmmer.py {params} {input} {output}
"""


rule get_neighbors:
    input:
        hmmer=rules.hmmer.output,
    output:
        neighbors=ensure(f"{RESULTS}/neighbors.tsv", non_empty=True),
    threads: workflow.cores
    params:
        N=N_NEIGHBORS,
        gdir=f"{RESULTS}/genomes",  # Se convertira en output
    shell:
        """
workflow/scripts/neighbors.R {threads} {params} {input} >| {output}
"""


rule all_faa:
    input:
        neighbors=rules.get_neighbors.output,
    output:
        faa=f"{RESULTS}/all.faa",
    params:
        faa_width=FAA_WIDTH,
        db=f"{RESULTS}/genomes",
    threads: workflow.cores
    shell:
        r"""
workflow/scripts/harvest.R {params} {threads} {input} >| {output}
"""


rule split_faa:
    input:
        faa=rules.all_faa.output,
    output:
        sentinel=f"{RESULTS}/.pieces_faa/split_faa.sentinel",
    params:
        pieces=f"{RESULTS}/.pieces_faa",
        batch_size=f"{BATCH_SIZE}",
        faa_width=f"{FAA_WIDTH}",
    run:
        #!/usr/bin/env python
        from datetime import datetime
        from pathlib import Path
        from shutil import rmtree

        from Bio import SeqIO

        START = datetime.today()

        IN_FAA = Path(f"{input.faa}")
        OUT_PIECES = Path(f"{params.pieces}")
        OUT_SENTINEL = Path(f"{output.sentinel}")
        BATCH_SIZE = int(f"{params.batch_size}")
        FAA_WIDTH = int(f"{params.faa_width}")
        FORMAT = "fasta"

        # main
        in_faa = SeqIO.parse(IN_FAA, FORMAT)
        if OUT_PIECES.exists():
            rmtree(OUT_PIECES)
        OUT_PIECES.mkdir()
        batch = []
        ibatch = 0


        def write(batch, out_file, wrap=60):
            with open(out_file, "w") as hout:
                w = SeqIO.FastaIO.FastaWriter(hout, wrap=wrap)
                for seq in batch:
                    w.write_record(seq)


        for idx, seq in enumerate(in_faa):
            batch.append(seq)

            if (idx + 1) % BATCH_SIZE == 0:
                ibatch += 1
                piece = OUT_PIECES / f"{ibatch}.faa"
                write(batch, piece, FAA_WIDTH)
                batch = []

        if len(batch) > 0:
            ibatch += 1
            piece = OUT_PIECES / f"{ibatch}.faa"
            write(batch, piece, FAA_WIDTH)

        END = datetime.today()
        with open(str(OUT_SENTINEL), "w") as h_sentinel:
            h_sentinel.write(f"{END- START}\n")


rule interproscan:
    input:
        sentinel=rules.split_faa.output.sentinel,
    output:
        iscan_raw=f"{RESULTS}/.iscan_raw.tsv",
    params:
        tmp="/tmp",
        pieces=f"{RESULTS}/.pieces_iscan",
        in_dir=f"{rules.split_faa.params.pieces}",
        interproscan_cmd=lambda wc: (
            str(Path(config.get("interproscan", "interproscan.sh")) / "interproscan.sh")
            if Path(config.get("interproscan", "interproscan.sh")).is_dir()
            else config.get("interproscan", "interproscan.sh")
        ),
    threads: workflow.cores
    cache: True
    shell:
        """
        set -x # Enable debug mode to print commands
        
        rm -rf {params.pieces}
        mkdir -p {params.pieces}
        
        # Check input files using bash arrays to avoid ls failures
        # Ensure nullglob is set so *.faa expands to nothing if no files match
        shopt -s nullglob
        files=({params.in_dir}/*.faa)
        count=${{#files[@]}}
        
        if [ "$count" -eq 0 ]; then
             echo "CRITICAL: No .faa files found in {params.in_dir}"
             exit 1
        fi
        
        echo "DEBUG: Found $count files in {params.in_dir}"
        
        for faa in "${{files[@]}}"; do
            echo "DEBUG: Running InterProScan on $faa"
            {params.interproscan_cmd} \\
                --input "$faa" \\
                --cpu {threads} \\
                --tempdir {params.tmp} \\
                --goterms \\
                --enable-tsv-residue-annot \\
                -dp \\
                -d {params.pieces} \\
                -f TSV || {{ echo "CRITICAL: InterProScan failed for $faa"; exit 1; }}
        done
        
        # Concatenate results
        cat {params.pieces}/*.tsv > {output.iscan_raw}
        """


rule add_header_iscan:
    input:
        iscan_raw=rules.interproscan.output,
    output:
        iscan=f"{RESULTS}/iscan.tsv",
    shell:
        """
# Annotate headers
workflow/scripts/add_header_iscan.R {params} {input} >| {output}
"""


rule get_archs:
    input:
        iscan=rules.add_header_iscan.output,
        neighbors=rules.get_neighbors.output,
    output:
        archs=f"{RESULTS}/archs.tsv",
    shell:
        """
workflow/scripts/archs.R {input} >| {output}
"""


rule get_absence_presence:
    input:
        taxa=rules.join_genomes_taxallnomy.output,
        proteins=rules.get_neighbors.output,
        domains=rules.get_archs.output.archs,
    output:
        absence_presence=f"{RESULTS}/absence_presence.tsv",
    shell:
        """
workflow/scripts/absence_presence.R {input} >| {output}
"""


rule get_hits:
    input:
        neighbors=rules.get_neighbors.output.neighbors,
        archs=rules.get_archs.output.archs,
    output:
        hits=f"{RESULTS}/hits.tsv",
    shell:
        """
workflow/scripts/archs_extended.R {input} >| {output}
"""




rule browser_iscan:
    input:
        iscan=f"{RESULTS}/iscan.tsv",
    output:
        db=f"{RESULTS}/browser_files/iscan.db",
    priority: 1
    shell:
        """
        python workflow/scripts/browser_iscan.py {input.iscan} {output.db}
        """



rule browser_metadata:
    input:
        metadata=f"{RESULTS}/genomes_metadata.tsv",
        # Force dependency on iscan to run sequentially
        prev=f"{RESULTS}/browser_files/iscan.db",
    output:
        db=f"{RESULTS}/browser_files/metadata.db",
    shell:
        """
        python workflow/scripts/browser_metadata.py {input.metadata} {output.db}
        """



rule browser_neighbors:
    input:
        neighbors=f"{RESULTS}/neighbors.tsv",
        # Force dependency on metadata to run sequentially
        prev=f"{RESULTS}/browser_files/metadata.db",
    output:
        db=f"{RESULTS}/browser_files/neighbors.db",
    shell:
        """
        python workflow/scripts/browser_neighbors.py {input.neighbors} {output.db}
        """
